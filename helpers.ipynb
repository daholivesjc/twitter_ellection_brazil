{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b2d821-0175-439e-ab49-c2d39d7a41f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings import BEARER_TOKEN, TWITTER_API_RECENT_SEARCH\n",
    "import requests\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "import sys, os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import torch\n",
    "from transformers import ( \n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# To set your environment variables in your terminal run the following line:\n",
    "# export 'BEARER_TOKEN'='<your_bearer_token>'\n",
    "# bearer_token = os.environ.get(\"BEARER_TOKEN\")\n",
    "\n",
    "def twitter_bearer_oauth(r):\n",
    "    \"\"\"\n",
    "    Method required by bearer token authentication.\n",
    "    \"\"\"\n",
    "\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {BEARER_TOKEN}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2RecentSearchPython\"\n",
    "    return r\n",
    "\n",
    "\n",
    "def get_twitter_params(query, end_time):\n",
    "    \n",
    "    tweet_fields = [\n",
    "        \"author_id\",\n",
    "        \"text\",\n",
    "        \"created_at\",\n",
    "        \"entities\",\n",
    "        \"geo\",\n",
    "        \"in_reply_to_user_id\",\n",
    "        \"lang,possibly_sensitive\",\n",
    "        \"referenced_tweets\",\n",
    "        \"source\",\n",
    "        \"public_metrics\"]\n",
    " \n",
    "    query_params = {\n",
    "        \"query\": query,\n",
    "        \"tweet.fields\": \",\".join(tweet_fields), \n",
    "        \"end_time\": end_time,\n",
    "        \"max_results\": 100\n",
    "    }\n",
    "        \n",
    "    return query_params\n",
    "\n",
    "\n",
    "def get_recents_tweets(logger, end_time, limit=10, query=\"\"):\n",
    "    \n",
    "    logger.info(query)\n",
    "    \n",
    "    params = get_twitter_params(query, end_time)\n",
    "    bearer_oauth = twitter_bearer_oauth\n",
    "    search_url = TWITTER_API_RECENT_SEARCH\n",
    "    \n",
    "    data_list = []\n",
    "    data_dict = {}\n",
    "    has_more = True\n",
    "    count = 1\n",
    "    while has_more:\n",
    "\n",
    "        if count <= limit:\n",
    "        \n",
    "            r = requests.get(search_url, auth=bearer_oauth, params=params)\n",
    "            response_dict = json.loads(r.text)\n",
    "            \n",
    "            logger.info(r.status_code)\n",
    "            \n",
    "            if response_dict[\"meta\"][\"result_count\"] > 0:\n",
    "                \n",
    "                if response_dict[\"meta\"].get('next_token',''):\n",
    "                    \n",
    "                    next_token = response_dict[\"meta\"][\"next_token\"]\n",
    "                    params[\"pagination_token\"] = next_token\n",
    "                \n",
    "                    data_dict = {\n",
    "                        \"query\": query,\n",
    "                        \"data\": response_dict[\"data\"],\n",
    "                        \"request_count\": count\n",
    "                    }\n",
    "                \n",
    "                    data_list.extend([data_dict])\n",
    "                \n",
    "                    count += 1\n",
    "                \n",
    "                else:\n",
    "                    has_more = False\n",
    "            \n",
    "            else:\n",
    "                has_more = False\n",
    "        \n",
    "        else:\n",
    "            has_more = False\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "\n",
    "def save_tweets_file(tweet_list):\n",
    "\n",
    "    path = os.path.abspath(os.path.join('..', '')) + \"/kali/twitter/twitter_ellection_brazil\"\n",
    "    \n",
    "    timestamp = int((datetime.utcnow() - timedelta(minutes = 4)).timestamp()*1e3)\n",
    "    \n",
    "    with open(f\"{path}/tweets/twitter_{timestamp}.lst\", \"wb\") as fp:\n",
    "        pickle.dump(tweet_list, fp)\n",
    "      \n",
    "\n",
    "def save_tweets_dataframe(dataframe, path_dataframe):\n",
    "\n",
    "    path = os.path.abspath(os.path.join('..', '')) + \"/kali/twitter/twitter_ellection_brazil\"\n",
    "    \n",
    "    timestamp = int((datetime.utcnow() - timedelta(minutes = 4)).timestamp()*1e3)\n",
    "    \n",
    "    # dataframe.to_pickle(f\"{path}/dataframe/dataframe_{timestamp}.pkl\")\n",
    "    \n",
    "    # dataframe.to_pickle(f\"{path_dataframe}/dataframe_{timestamp}.pkl\")\n",
    "    \n",
    "    dataframe.to_csv(f\"{path_dataframe}/dataframe_{timestamp}.csv\",encoding=\"utf-8\", sep=\";\")\n",
    "    \n",
    "    print(\"Dataframe Tweets saved successfully!\")\n",
    "        \n",
    "def delete_tweets_file(files):\n",
    "    \n",
    "    for file in files:\n",
    "        \n",
    "        try:\n",
    "            os.remove(file)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "def read_tweet_files():\n",
    "\n",
    "    path = os.path.abspath(os.path.join('..', '')) + \"/kali/twitter/twitter_ellection_brazil\"\n",
    "    \n",
    "    files = glob.glob(f'{path}/tweets/*.lst', recursive = True)\n",
    "    \n",
    "    if not files:\n",
    "        \n",
    "        print(\"There are no files to be processed!\")\n",
    "        sys.exit()\n",
    "\n",
    "    data_list = []\n",
    "    data = {}\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        \n",
    "        with open(file, \"rb\") as fp: \n",
    "            try:     \n",
    "                file_data = pickle.load(fp)\n",
    "                data_list.extend(file_data)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    twitter_list = []\n",
    "    twitter_list_mentions = []\n",
    "    twitter_list_annotations = []\n",
    "    twitter_list_urls = []\n",
    "    twitter_list_hashtags = []\n",
    "    twitter_list_cashtags = []\n",
    "    twitter_list_public_metrics = []\n",
    "    twitter_list_referenced_tweets = []\n",
    "\n",
    "    for twitter in data_list:\n",
    "        for tweet in twitter[\"data\"]:\n",
    "        \n",
    "            data = {\n",
    "                \"author_id\": tweet[\"author_id\"],\n",
    "                \"created_at\": tweet[\"created_at\"],\n",
    "                \"twitter_id\": tweet[\"id\"],\n",
    "                \"lang\": tweet[\"lang\"],\n",
    "                \"possibly_sensitive\": tweet[\"possibly_sensitive\"],\n",
    "                \"source\": tweet[\"source\"],\n",
    "                \"text\": tweet[\"text\"],\n",
    "                \"query\": twitter[\"query\"],\n",
    "                \"request_count\": twitter[\"request_count\"]\n",
    "            }\n",
    "               \n",
    "            if tweet.get('referenced_tweets',''):\n",
    "        \n",
    "                for refer in tweet[\"referenced_tweets\"]:\n",
    "                    \n",
    "                    referenced_tweets = {\n",
    "                        \"twitter_id\": tweet[\"id\"],\n",
    "                        \"referenced_tweets_type\": refer[\"type\"],\n",
    "                        \"referenced_tweets_id\": refer[\"id\"]\n",
    "                    }\n",
    "                    \n",
    "                    twitter_list_referenced_tweets.append(referenced_tweets)\n",
    "            \n",
    "            if tweet.get('public_metrics',''):\n",
    "                \n",
    "                public_metrics = {\n",
    "                    \"twitter_id\": tweet[\"id\"],\n",
    "                    \"like_count\": tweet[\"public_metrics\"][\"like_count\"],\n",
    "                    \"quote_count\": tweet[\"public_metrics\"][\"quote_count\"],\n",
    "                    \"reply_count\": tweet[\"public_metrics\"][\"reply_count\"],\n",
    "                    \"retweet_count\": tweet[\"public_metrics\"][\"retweet_count\"]\n",
    "                }\n",
    "                \n",
    "                twitter_list_public_metrics.append(public_metrics)\n",
    "        \n",
    "        \n",
    "            if tweet.get('entities',''):\n",
    "                \n",
    "                if tweet[\"entities\"].get('annotations',''):\n",
    "                    \n",
    "                    for annot in tweet[\"entities\"].get('annotations',''):\n",
    "                        \n",
    "                        annotations = {\n",
    "                            \"twitter_id\": tweet[\"id\"],\n",
    "                            \"annotations_normalized_text\": annot[\"normalized_text\"],\n",
    "                            \"annotations_probability\": annot[\"probability\"],\n",
    "                            \"annotations_type\": annot[\"type\"]\n",
    "                        }\n",
    "                        \n",
    "                        twitter_list_annotations.append(annotations)\n",
    "                        \n",
    "                if tweet[\"entities\"].get('mentions',''):\n",
    "                    \n",
    "                    for ment in tweet[\"entities\"].get('mentions',''):\n",
    "                        \n",
    "                        mentions = {\n",
    "                            \"twitter_id\": tweet[\"id\"],\n",
    "                            \"mentions_id\": ment[\"id\"],\n",
    "                            \"mentions_username\": ment[\"username\"]\n",
    "                        }\n",
    "                        \n",
    "                        twitter_list_mentions.append(mentions)\n",
    "        \n",
    "                if tweet[\"entities\"].get('urls',''):\n",
    "            \n",
    "                    for url in tweet[\"entities\"].get('urls',''):\n",
    "                        \n",
    "                        urls = {\n",
    "                            \"twitter_id\": tweet[\"id\"],\n",
    "                            \"urls_display_url\": url[\"display_url\"],\n",
    "                            \"urls_expanded\": url[\"expanded_url\"],\n",
    "                            \"urls_url\": url[\"url\"]\n",
    "                        }\n",
    "            \n",
    "                        twitter_list_urls.append(urls)\n",
    "                        \n",
    "                \n",
    "                if tweet[\"entities\"].get('hashtags',''):\n",
    "            \n",
    "                    for hashtag in tweet[\"entities\"].get('hashtags',''):\n",
    "                        \n",
    "                        hashtags = {\n",
    "                            \"twitter_id\": tweet[\"id\"],\n",
    "                            \"hashtags_tag\": hashtag[\"tag\"]\n",
    "                        }\n",
    "            \n",
    "                        twitter_list_hashtags.append(hashtags)\n",
    "                \n",
    "                if tweet[\"entities\"].get('cashtags',''):\n",
    "            \n",
    "                    for cash in tweet[\"entities\"].get('cashtags',''):\n",
    "                        \n",
    "                        cashtags = {\n",
    "                            \"twitter_id\": tweet[\"id\"],\n",
    "                            \"cashtags_tag\": cash[\"tag\"]\n",
    "                        }\n",
    "            \n",
    "                        twitter_list_cashtags.append(cashtags)\n",
    "        \n",
    "            twitter_list.append(data)\n",
    "            \n",
    "    # dataframes\n",
    "    df_twitter = pd.DataFrame(twitter_list)\n",
    "    df_annotations = pd.DataFrame(twitter_list_annotations)\n",
    "    df_cashtags = pd.DataFrame(twitter_list_cashtags)\n",
    "    df_hashtags = pd.DataFrame(twitter_list_hashtags)\n",
    "    df_mentions = pd.DataFrame(twitter_list_mentions)\n",
    "    df_urls = pd.DataFrame(twitter_list_urls)\n",
    "    df_public_metrics = pd.DataFrame(twitter_list_public_metrics)\n",
    "    df_referenced_tweets = pd.DataFrame(twitter_list_referenced_tweets)\n",
    "    \n",
    "    # merge data\n",
    "    if not df_annotations.empty:\n",
    "        dataframe = df_twitter.merge(df_annotations,how=\"left\",on=\"twitter_id\")\n",
    "    \n",
    "    if not df_cashtags.empty:\n",
    "        dataframe = dataframe.merge(df_cashtags,how=\"left\",on=\"twitter_id\")\n",
    "        \n",
    "    if not df_hashtags.empty:\n",
    "        dataframe = dataframe.merge(df_hashtags,how=\"left\",on=\"twitter_id\")\n",
    "        \n",
    "    if not df_mentions.empty:  \n",
    "        dataframe = dataframe.merge(df_mentions,how=\"left\",on=\"twitter_id\")\n",
    "        \n",
    "    if not df_urls.empty:    \n",
    "        dataframe = dataframe.merge(df_urls,how=\"left\",on=\"twitter_id\")\n",
    "        \n",
    "    if not df_public_metrics.empty:    \n",
    "        dataframe = dataframe.merge(df_public_metrics,how=\"left\",on=\"twitter_id\")\n",
    "        \n",
    "    if not df_referenced_tweets.empty:    \n",
    "        dataframe = dataframe.merge(df_referenced_tweets,how=\"left\",on=\"twitter_id\")\n",
    "        \n",
    "    delete_tweets_file(files)   \n",
    "    \n",
    "    print(\"Files with successfully processed Tweets!\")\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def clean_text(texto):\n",
    "    \n",
    "    punct = string.punctuation # Cria uma tabela de tradução\n",
    "    trantab = str.maketrans(punct, len(punct)*' ') # Todo simbolo da pontuação e substituido por um espaço\n",
    "    \n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\"]+\", re.UNICODE)\n",
    "    \n",
    "    texto = re.sub('\\d+', '', str(texto)).replace(\"&gt;\",\" \").replace(\"&lt;\",\" \") \n",
    "    texto = re.sub(r\"https?:\\/\\/\\S+\",\"\", texto)\n",
    "    texto = re.sub(r\"@[A-Za-z0-9\\w]+\",\"\", texto)\n",
    "    texto = re.sub('^RT ',' ',texto)\n",
    "    texto = texto.translate(trantab).replace(\"\\n\",\" \")\n",
    "    texto = re.sub(emoj, '', texto).replace(\"“\",\" \").replace(\"”\",\" \").strip().lower()\n",
    "    \n",
    "    return \" \".join(texto.split())\n",
    "\n",
    "\n",
    "def get_sentiment(row, token_obj, model_obj):\n",
    "    \n",
    "    print(row.name)\n",
    "    \n",
    "    tokens = token_obj.encode(row.text_english, return_tensors='pt')\n",
    "    \n",
    "    result = model_obj(tokens)\n",
    "          \n",
    "    result.logits\n",
    "    \n",
    "    return int(torch.argmax(result.logits))+1\n",
    "\n",
    "\n",
    "def get_bert_model():\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "    \n",
    "    return {\n",
    "        \"tokenizer\": tokenizer,\n",
    "        \"model\": model\n",
    "    }\n",
    "    \n",
    "# https://medium.com/@morganjonesartist/color-guide-to-seaborn-palettes-da849406d44f\n",
    "\n",
    "def chart_tweets(df, x, y1, y2, x_title, y1_title, y2_title, title):\n",
    "    \n",
    "    x = df[x].values\n",
    "    y1 = df[y1].values\n",
    "    y2 = df[y2].values\n",
    "    \n",
    "    total = df[\"qtde\"].sum()\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.xticks(rotation=45)\n",
    "    ax = sns.barplot(x = x, y = y1, data = df,palette=\"BrBG\")\n",
    "    ax.set_ylabel(y1_title, fontsize=16)\n",
    "    ax.set_xlabel(x_title, fontsize=16)\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.set_ylabel(y2_title, fontsize=16)\n",
    "    ax2.set_ylim(0,1)\n",
    "\n",
    "    sns.lineplot(x=x, y=y2, data=df, marker='o', color='crimson', lw=3, ax=ax2)\n",
    "    \n",
    "    for x, y in zip(df[\"query\"], df[\"_%\"]):\n",
    "        plt.text(x = x, y = y, s = '{:1.1f}%'.format(y*100),color = 'black', fontsize=14)\n",
    "        \n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
